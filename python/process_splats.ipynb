{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "# Global constant for grid step size\n",
    "GRID_STEP = 1\n",
    "\n",
    "def create_grid_cells(vertex_data_1, vertex_data_2):\n",
    "    # Combine all points to find global min/max\n",
    "    all_points = np.vstack((vertex_data_1, vertex_data_2))\n",
    "    \n",
    "    # Find min and max coordinates\n",
    "    min_coords = np.min(all_points, axis=0)\n",
    "    max_coords = np.max(all_points, axis=0)\n",
    "    \n",
    "    # Initialize lists for box vertices and indices\n",
    "    boxes_vertices = []\n",
    "    occupied_cells = {}  # Changed to dict to store z ranges\n",
    "    \n",
    "    # Find occupied cells and track z ranges\n",
    "    for point in all_points:\n",
    "        ix = int((point[0] - min_coords[0]) // GRID_STEP)\n",
    "        iy = int((point[1] - min_coords[1]) // GRID_STEP)\n",
    "        cell_key = (ix, iy)\n",
    "        \n",
    "        if cell_key not in occupied_cells:\n",
    "            occupied_cells[cell_key] = {'min_z': point[2], 'max_z': point[2]}\n",
    "        else:\n",
    "            occupied_cells[cell_key]['min_z'] = min(occupied_cells[cell_key]['min_z'], point[2])\n",
    "            occupied_cells[cell_key]['max_z'] = max(occupied_cells[cell_key]['max_z'], point[2])\n",
    "    \n",
    "    # Create vertices for occupied cells\n",
    "    for (ix, iy), z_range in occupied_cells.items():\n",
    "        x = min_coords[0] + ix * GRID_STEP\n",
    "        y = min_coords[1] + iy * GRID_STEP\n",
    "        z_min = z_range['min_z']\n",
    "        z_max = z_range['max_z']\n",
    "        \n",
    "        # Create box vertices\n",
    "        boxes_vertices.extend([\n",
    "            # Bottom face\n",
    "            [x, y, z_min], [x + GRID_STEP, y, z_min],\n",
    "            [x + GRID_STEP, y, z_min], [x + GRID_STEP, y + GRID_STEP, z_min],\n",
    "            [x + GRID_STEP, y + GRID_STEP, z_min], [x, y + GRID_STEP, z_min],\n",
    "            [x, y + GRID_STEP, z_min], [x, y, z_min],\n",
    "            # Top face\n",
    "            [x, y, z_max], [x + GRID_STEP, y, z_max],\n",
    "            [x + GRID_STEP, y, z_max], [x + GRID_STEP, y + GRID_STEP, z_max],\n",
    "            [x + GRID_STEP, y + GRID_STEP, z_max], [x, y + GRID_STEP, z_max],\n",
    "            [x, y + GRID_STEP, z_max], [x, y, z_max],\n",
    "            # Vertical edges\n",
    "            [x, y, z_min], [x, y, z_max],\n",
    "            [x + GRID_STEP, y, z_min], [x + GRID_STEP, y, z_max],\n",
    "            [x + GRID_STEP, y + GRID_STEP, z_min], [x + GRID_STEP, y + GRID_STEP, z_max],\n",
    "            [x, y + GRID_STEP, z_min], [x, y + GRID_STEP, z_max],\n",
    "        ])\n",
    "    \n",
    "    return np.array(boxes_vertices)\n",
    "\n",
    "# Function to load and sample every 10,000th vertex from a .ply file\n",
    "def load_sampled_ply(file_path, sample_step=10000):\n",
    "    ply_data = PlyData.read(file_path)\n",
    "    vertex_data = []\n",
    "    for i, v in enumerate(ply_data['vertex'].data):\n",
    "        if i % sample_step == 0:\n",
    "            vertex_data.append((v['x'], v['y'], v['z']))\n",
    "    return np.array(vertex_data)\n",
    "\n",
    "# Load and sample the first .ply file\n",
    "vertex_data_1 = load_sampled_ply('splats/trained_export_m7_1_8_adc.ply')\n",
    "\n",
    "# Load and sample the second .ply file\n",
    "vertex_data_2 = load_sampled_ply('splats/trained_export_m7_2_8_adc.ply')\n",
    "\n",
    "# Calculate the range of each axis for aspect ratio\n",
    "x_range = max(vertex_data_1[:, 0].max(), vertex_data_2[:, 0].max()) - min(vertex_data_1[:, 0].min(), vertex_data_2[:, 0].min())\n",
    "y_range = max(vertex_data_1[:, 1].max(), vertex_data_2[:, 1].max()) - min(vertex_data_1[:, 1].min(), vertex_data_2[:, 1].min())\n",
    "z_range = max(vertex_data_1[:, 2].max(), vertex_data_2[:, 2].max()) - min(vertex_data_1[:, 2].min(), vertex_data_2[:, 2].min())\n",
    "aspect_ratio = dict(x=x_range, y=y_range, z=z_range)\n",
    "\n",
    "\n",
    "grid_vertices = create_grid_cells(vertex_data_1, vertex_data_2)\n",
    "# Add grid trace\n",
    "grid_trace = go.Scatter3d(\n",
    "    x=grid_vertices[:, 0],\n",
    "    y=grid_vertices[:, 1],\n",
    "    z=grid_vertices[:, 2],\n",
    "    mode='lines',\n",
    "    line=dict(color='gray', width=1),\n",
    "    name='Grid',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "\n",
    "# Create 3D scatter plots for each point cloud\n",
    "trace1 = go.Scatter3d(\n",
    "    x=vertex_data_1[:, 0],\n",
    "    y=vertex_data_1[:, 1],\n",
    "    z=vertex_data_1[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='blue',\n",
    "        opacity=0.5\n",
    "    ),\n",
    "    name='Point Cloud 1'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter3d(\n",
    "    x=vertex_data_2[:, 0],\n",
    "    y=vertex_data_2[:, 1],\n",
    "    z=vertex_data_2[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='red',\n",
    "        opacity=0.5\n",
    "    ),\n",
    "    name='Point Cloud 2'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='X'),\n",
    "        yaxis=dict(title='Y'),\n",
    "        zaxis=dict(title='Z'),\n",
    "        aspectratio=aspect_ratio\n",
    "    ),\n",
    "    title='Interactive 3D Point Cloud Visualization of Two Files'\n",
    ")\n",
    "\n",
    "\n",
    "def export_grid_cells(input_ply_path, grid_step=GRID_STEP, export_cells=True, export_json=True):\n",
    "    # Create output directory\n",
    "    output_dir = f\"grid-{grid_step}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read input PLY file\n",
    "    print(f\"Reading {input_ply_path}...\")\n",
    "    ply_data = PlyData.read(input_ply_path)\n",
    "    vertex_data = ply_data['vertex'].data\n",
    "    \n",
    "    # Calculate global min/max coordinates\n",
    "    x_coords = vertex_data['x']\n",
    "    y_coords = vertex_data['y']\n",
    "    z_coords = vertex_data['z']\n",
    "    min_x, max_x = np.min(x_coords), np.max(x_coords)\n",
    "    min_y, max_y = np.min(y_coords), np.max(y_coords)\n",
    "    min_z, max_z = np.min(z_coords), np.max(z_coords)\n",
    "    avg_z = np.mean(z_coords)\n",
    "\n",
    "        # Get all occupied cells\n",
    "    cell_vertices = {}\n",
    "    for vertex in vertex_data:\n",
    "        cell_x = int(vertex['x'] // grid_step)\n",
    "        cell_y = int(vertex['y'] // grid_step)\n",
    "        cell_key = (cell_x, cell_y)\n",
    "        if cell_key not in cell_vertices:\n",
    "            cell_vertices[cell_key] = []\n",
    "        cell_vertices[cell_key].append(vertex)\n",
    "    \n",
    "  \n",
    "    # Prepare JSON data\n",
    "    json_data = {\n",
    "        \"version\": \"2024-11-13\",\n",
    "        \"patches\": [{\n",
    "            \"patch\": Path(input_ply_path).name,  # Only the filename without path\n",
    "            \"grid_step\": grid_step,\n",
    "            \"min_x\": float(min_x),\n",
    "            \"min_y\": float(min_y),\n",
    "            \"max_x\": float(max_x),\n",
    "            \"max_y\": float(max_y),\n",
    "            \"min_z\": float(min_z),\n",
    "            \"max_z\": float(max_z),\n",
    "            \"average_z\": float(avg_z),\n",
    "            \"cells\": [[int(x), int(y)] for x, y in cell_vertices.keys()]  # Add list of occupied cells\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    # Export JSON if requested\n",
    "    if export_json:\n",
    "        json_path = str(Path(input_ply_path).with_suffix('.json'))\n",
    "        import json\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(obj=json_data, fp=f, indent=4, sort_keys=True)\n",
    "        print(f\"JSON metadata saved to {json_path}\")\n",
    "    \n",
    "\n",
    "    # Export PLY cells if requested\n",
    "    if export_cells:\n",
    "        # Get base filename without extension\n",
    "        base_name = Path(input_ply_path).stem\n",
    "        \n",
    "        # Create dictionary to store vertices by cell\n",
    "        cell_vertices = {}\n",
    "        \n",
    "        # Process vertices and assign to cells\n",
    "        print(\"Assigning vertices to cells...\")\n",
    "        for vertex in tqdm(vertex_data):\n",
    "            cell_x = int(vertex['x'] // grid_step)\n",
    "            cell_y = int(vertex['y'] // grid_step)\n",
    "            cell_key = (cell_x, cell_y)\n",
    "            \n",
    "            if cell_key not in cell_vertices:\n",
    "                cell_vertices[cell_key] = []\n",
    "            cell_vertices[cell_key].append(vertex)\n",
    "        \n",
    "        # Export each cell as a separate PLY file\n",
    "        print(\"Exporting cell files...\")\n",
    "        for (cell_x, cell_y), vertices in tqdm(cell_vertices.items()):\n",
    "            vertex_array = np.array(vertices, dtype=vertex_data.dtype)\n",
    "            vertex_element = PlyElement.describe(vertex_array, 'vertex')\n",
    "            \n",
    "            output_filename = f\"{base_name}_{grid_step}s_{cell_x}x_{cell_y}y.ply\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            PlyData([vertex_element], text=False).write(output_path)\n",
    "        \n",
    "        print(f\"Export complete! Files saved in {output_dir}/\")\n",
    "        print(f\"Total cells created: {len(cell_vertices)}\")\n",
    "\n",
    "# Example usage with only JSON export enabled:\n",
    "export_grid_cells('splats/trained_export_m7_1_8_adc.ply', export_cells=False, export_json=True)\n",
    "# # Update figure with grid\n",
    "# fig = go.Figure(data=[trace1, trace2, grid_trace], layout=layout)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting .ply to .ksplat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "\n",
    "_PATH = \"/Users/nsv/wildflowai/wildflow-3d\"\n",
    "\n",
    "def convert_ply_files(overwrite=False):\n",
    "    # Input and output directories\n",
    "    input_dir = Path(f\"{_PATH}/public/grid-1\")\n",
    "    output_dir = Path(f\"{_PATH}/public/grid-1-ksplat\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all .ply files\n",
    "    ply_files = list(input_dir.glob(\"*.ply\"))\n",
    "    \n",
    "    # Filter out files that already exist if overwrite is False\n",
    "    if not overwrite:\n",
    "        ply_files = [f for f in ply_files if not (output_dir / f\"{f.stem}.ksplat\").exists()]\n",
    "        if not ply_files:\n",
    "            print(\"All files already converted. Use --overwrite to reconvert.\")\n",
    "            return\n",
    "\n",
    "    # Process each file with progress bar\n",
    "    for ply_file in tqdm(ply_files, desc=\"Converting PLY files\"):\n",
    "        # Create output filename\n",
    "        output_file = output_dir / f\"{ply_file.stem}.ksplat\"\n",
    "        \n",
    "        if not overwrite and output_file.exists():\n",
    "            tqdm.write(f\"Skipping {ply_file.name} (already exists)\")\n",
    "            continue\n",
    "            \n",
    "        # Construct the command\n",
    "        command = [\n",
    "            \"node\",\n",
    "            \"--max-old-space-size=8192\",\n",
    "            \"util/create-ksplat.js\",\n",
    "            str(ply_file),\n",
    "            str(output_file),\n",
    "            \"1\",  # compression level\n",
    "            \"5\",  # alpha removal threshold\n",
    "            \"0,0,0\",  # scene center\n",
    "            \"5.0\",  # block size\n",
    "            \"256\",  # bucket size\n",
    "            \"0\"  # spherical harmonics level\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # Run the command from GaussianSplats3D directory\n",
    "            subprocess.run(\n",
    "                command,\n",
    "                check=True,\n",
    "                cwd=Path(f\"{_PATH}/GaussianSplats3D\"),\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE\n",
    "            )\n",
    "            tqdm.write(f\"Successfully converted {ply_file.name}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            tqdm.write(f\"Error converting {ply_file.name}: {e}\")\n",
    "            tqdm.write(f\"Error output: {e.stderr.decode()}\")\n",
    "\n",
    "    print(\"\\nConversion complete!\")\n",
    "    print(f\"Processed {len(ply_files)} files\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Convert PLY files to KSPLAT format')\n",
    "    parser.add_argument('--overwrite', action='store_true', \n",
    "                      help='Overwrite existing KSPLAT files')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    convert_ply_files(overwrite=args.overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "\n",
    "_PATH = \"/Users/nsv/wildflowai/wildflow-3d\"\n",
    "\n",
    "def convert_ply_files(overwrite=False):\n",
    "    # Input and output directories\n",
    "    input_dir = Path(f\"{_PATH}/public/grid-1\")\n",
    "    output_dir = Path(f\"{_PATH}/public/grid-1-ksplat\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all .ply files\n",
    "    ply_files = list(input_dir.glob(\"*.ply\"))\n",
    "    \n",
    "    # Filter out files that already exist if overwrite is False\n",
    "    if not overwrite:\n",
    "        ply_files = [f for f in ply_files if not (output_dir / f\"{f.stem}.ksplat\").exists()]\n",
    "        if not ply_files:\n",
    "            print(\"All files already converted. Use overwrite=True to reconvert.\")\n",
    "            return\n",
    "\n",
    "    # Process each file with progress bar\n",
    "    errors = []\n",
    "    for ply_file in tqdm(ply_files, desc=\"Converting PLY files\"):\n",
    "        # Create output filename\n",
    "        output_file = output_dir / f\"{ply_file.stem}.ksplat\"\n",
    "            \n",
    "        # Construct the command\n",
    "        command = [\n",
    "            \"node\",\n",
    "            \"--max-old-space-size=8192\",\n",
    "            \"util/create-ksplat.js\",\n",
    "            str(ply_file),\n",
    "            str(output_file),\n",
    "            \"1\",  # compression level\n",
    "            \"5\",  # alpha removal threshold\n",
    "            \"0,0,0\",  # scene center\n",
    "            \"5.0\",  # block size\n",
    "            \"256\",  # bucket size\n",
    "            \"0\"  # spherical harmonics level\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # Run the command from GaussianSplats3D directory\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                check=True,\n",
    "                cwd=Path(f\"{_PATH}/GaussianSplats3D\"),\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            errors.append((ply_file.name, e.stderr))\n",
    "\n",
    "    # Only show errors if there were any\n",
    "    if errors:\n",
    "        print(\"\\nErrors occurred during conversion:\")\n",
    "        for filename, error in errors:\n",
    "            print(f\"\\nError converting {filename}:\")\n",
    "            print(error)\n",
    "\n",
    "    print(f\"\\nConversion complete! Processed {len(ply_files)} files with {len(errors)} errors.\")\n",
    "\n",
    "# Example usage:\n",
    "convert_ply_files(overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
